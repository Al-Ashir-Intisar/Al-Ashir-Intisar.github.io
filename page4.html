<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Ethics Privacy & Safety</title>
    <link rel="stylesheet" href="page.css" />
  </head>
  <body>
    <div class="content">
      <h1>Privacy, Safety, and Ethical Implications:</h1>

      <section>
        <h2>
          Large Language Models (LLMs) in Healthcare and Privacy Concerns:
        </h2>
        <p>
          Recent researches on the use of LLMs in health care, marked improved
          accuracy and clinical relevance of responses from LLMs such as GPT-4,
          especially in addressing complex health care inquiries. The improved
          accuracy and clinical relevance with LLMs mark a paradigm shift in
          digital health tools and Virtual Assistants (VAs). Such LLM are
          already being adapted and integrated into existing VA platforms,
          offering cost-effective, scalable, and inclusive solutions. This
          increased application of LLMs in healthcare comes with increased risks
          as we move toward more personalized digital health ecosystems.
          Therefore, a thorough understanding of the implications of LLM use is
          necessary by healthcare professionals to patients to develop and
          adhere to ethical guidelines, regulatory frameworks, governance
          principles, and privacy and safety measures.
        </p>
        <p>
          Sources: Sezgin, Emre. “Redefining Virtual Assistants in Health Care:
          The Future With Large Language Models.” Journal of Medical Internet
          Research, vol. 26, no. 7, 2024, pp. e53225–e53225,
          https://doi.org/10.2196/53225.
        </p>
        <p>
          Large language models (LLMs) have been shown to memorize parts of
          their training data, and when prompted appropriately, they will emit
          the memorized training data verbatim. This is concerning because it
          can violate patient privacy (exposing sensitive data), degrades , and
          sometimes hurts fairness (some texts are memorized over others).
          Memorization capability of LLMs significantly grows as (1) the
          capacity of a model increases, (2) the number of times an example has
          been duplicated increases, and (3) the number of tokens of context
          used to prompt the model. Overall, memorization in LLMs is more
          prevalent than previously believed and will likely get worse as models
          continues to scale, at least without active mitigations Carlini et al.
          (2022).
        </p>
        <p>
          Source: Nicholas Carlini, Daphne Ippolito, Matthew Jagielski,
          Katherine Lee, Florian Tramer, and Chiyuan Zhang. 2022. Quantifying
          memorization across neural language models. arXiv preprint
          arXiv:2202.07646
        </p>
        <h3>Differential Privacy:</h3>
        <p>
          Differential Privacy is a relatively new approach to
          privacy-preserving data analysis which ensures that (almost, and
          quantifiably) no risk is incurred by joining a statistical database.
          Application of differential privacy to the data used for these LLMs
          training can reduce the risk of private information leaks. The idea is
          to preserve privacy by adding enough noise to the original data so
          that individuals can not be identified but also the noise does not
          affect the integrity of the analysis done over the data.
        </p>
        <p>
          Source: Dwork, Cynthia. “Differential Privacy: A Survey of Results.”
          Theory and Applications of Models of Computation, Springer Berlin
          Heidelberg, pp. 1–19, https://doi.org/10.1007/978-3-540-79228-4_1.
        </p>

        <div class="accordion">
          <button class="accordion-btn">Differential Privacy Simulation</button>
          <div class="panel">
            <div>
              <li></li>
              <button onclick="generateData()" class="sim_button">
                Generate 500 Random Observations
              </button>
              <button onclick="calculateTrueProportions()" class="sim_button">
                Calculate True Proportions
              </button>
              <button onclick="simulateSurvey()" class="sim_button">
                Simulate Survey Methods
              </button>
              <button
                onclick="calculateSurveyedProportions()"
                class="sim_button"
              >
                Calculate Surveyed Proportions
              </button>
            </div>

            <div id="data"></div>

            <div id="results">
              <h2>Results</h2>
              <p>
                Actual proportion of men who cheat:
                <span id="actualProportion"></span>
              </p>
              <p>
                Proportion calculated from surveyed data:
                <span id="surveyedProportion"></span>
              </p>
              <p>
                3/4 of the proportion calculated from surveyed data:
                <span id="trueYesProportion"></span>
              </p>
            </div>
          </div>
        </div>
      </section>

      <section>
        <h2>Ethics of Personalized Medicine</h2>
        <p>
          Personalized medicine, enabled by AI and genomic technologies, holds
          great promise for tailored treatments and improved patient outcomes.
          However, it also raises ethical considerations. Questions arise
          regarding equitable access to personalized treatments, potential
          biases in algorithms, and the implications of genetic information on
          privacy and discrimination.
        </p>
        <p>Sources: <a href="#">Source 3</a>, <a href="#">Source 4</a></p>
      </section>

      <section>
        <h2>Ethics of AI Decision Making in Healthcare</h2>
        <p>
          AI decision-making systems in healthcare have the potential to enhance
          diagnostic accuracy, treatment planning, and resource allocation.
          However, ethical dilemmas emerge concerning transparency,
          accountability, and the balance between algorithmic recommendations
          and human judgment. Additionally, biases embedded in training data can
          perpetuate disparities in healthcare delivery.
        </p>
        <p>Sources: <a href="#">Source 5</a>, <a href="#">Source 6</a></p>
      </section>
    </div>

    <script src="page4.js"></script>
  </body>
</html>
